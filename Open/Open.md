开题讲稿：
`First of all`
各位老师，各位同学大家好，今天我开题答辩的题目是《双目视觉立体匹配算法设计与实现》
我的答辩将从课题目的，实现方法，进度安排三个部分来进行

`课题目的`
首先第一部分课题目的
近年来，随着无人驾驶技术，智能机器人的发展，二维平面图像的数据，已经无法满足现在应用需求。

`如何从二维的图像中提取三维的深度信息？`
开始成为一个重要的命题。

虽然自20世纪60年代以来，不断有人提出不同的方法来提取二维图像中的三维深度信息。

但是目前准确率较高的传统的方法如激光测距仪，结构光等，有的设备非常昂贵，有的使用场景受限

例如目前谷歌无人驾驶车使用的激光雷达，造价高达一万两千美金，相较于普通摄像头几十到一两百美金的成本来说， 这个还是个天文数字

而设备简单的传统双目视觉方法，受限于立体匹配算法的不成熟，又无法提供准确的视差数据。如目前常用的opencv和matlab的半全局SAD块匹配算法，误差率高达29%
远远无法满足实际应用的需求。

在无人驾驶和机器人导航等技术迅猛发展的今天，我们亟需设计一个能从成本低廉的设备中提取准确率较高的立体视觉算法。

也就是我们今天提出这个课题的意义所在。！！

`实现方法`
接下来，
在介绍我们的双目视觉匹配算法之前简单的介绍一下视差理论。

视差指的是同一对象在左图像和右图像中的水平位置的差异
下图是一个理想状况中的双目视觉系统。

公式

上式中，f是相机的焦距，B是相机中心之间的距离

我给大家详细介绍一下我们双目视觉立体匹配算法的大致实现方法
整个双目视觉方法大致分为，
离线标定，双目相机矫正，立体匹配，以及3D恢复

由于我们使用的成本低廉的双目相机，存在光学畸变，以及我们使用的双目相机，并不能做到绝对的水平，所以需要通过棋盘标定法来进行离线标定，
标定所得的光学参数和位置矩阵用于矫正获取的双目图像。
我们采用matlab进行；离线标定，因为opencv的标定会在垂直方向上造成最多9个像素的误差。

经过矫正的图像作为输入进行立体匹配。
立体匹配所得的视差图，再通过opencv进行3D恢复

上述步骤中的重点是立体匹配的算法，也就是我们研究的重点。

我们对左图中的每个像素点，

在可能的视差范围内，从右图中依次提取出9×9的图像块，

通过一个权值共享的暹罗网络提取两图像块的特征，
经过L2范数归一化，点积后得到相似性得分，选取相似性得分最高的点，作为匹配点，

最后所得的视差图还需要左右一致性检查，半全局匹配，中值滤波和双边滤波等后处理进一步优化。

`进度安排`
下面我们的进度安排，和大家都差不多。

目前我们的立体匹配所得的视差图误差大概在11.7%左右。
