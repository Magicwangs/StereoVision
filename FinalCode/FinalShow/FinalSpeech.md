
各位老师大家好！
我是答辩人王灏，我的论文题目是双目视觉立体匹配算法设计与实现

我将从以下五个方面来介绍我的论文

首先是论文的研究背景及意义，

立体视觉技术一直是计算机视觉领域中的一个重要分支，特别是近年来，随着无人驾驶，工业自动化以及机器人技术的发展，

“如何从二维图像中提取出三维的深度信息”  成为一个重要的命题。

目前业界主流的立体视觉方案主要分为两大类，

第一种方式是，通过激光雷达获取三维信息，测量精度高，测量距离远，对周围环境适应性高，非常适合室外场合使用。目前谷歌、特斯拉等公司开发的无人驾驶车均使用了Velodyne的激光雷达，售价在8千到8万美元不等。

但是激光雷达无法感知无距离差距的平面信息，体积较大，价格昂贵，且垂直视角受限，无法得到真正的普及。

第二种方式则是通过摄像头获取，分析得到三维信息，这种方式可以获取丰富的三维信息，且价格低廉，体积较小，如大疆的无人机就是采用的是双目避障技术。  但是目前立体匹配算法还不成熟，易受光照等外部条件影响。

在无人驾驶，机器人导航等技术迅猛发展的今天，我们亟需设计一个能从成本低廉的设备中提取的准确率较高的立体视觉算法。

接下来给大家简单介绍一下双目立体视觉原理

假设存在这样一个理想的双目视觉模型，左右两摄像机平行摆放，摄像机内参一致，左右摄像机成像平面位于同一平面中。
其中P和P'点是真实世界的点P在左右图中的投影点，Xr-Xt我们称之为视差d，
b是左右光心的距离，f是焦距，Z是我们想要知道的深度信息。

我们通过简单的相似三角形原理可以得出以上公式，若已知b，f，d，我们就可以得到深度信息Z。

不难看出，双目立体视觉的实现难点在于 如何寻找左右图中的匹配点。也就是本文的研究重点，双目立体匹配算法。

在详细介绍本文采用的立体匹配算法之前，我简单介绍一下本文使用数据集的构造

目前主流的立体视觉数据集有KITTI和Middlebury数据集两种
KITTI：N1是视差误差超过三个像素点的像素点的个数，N2是所有有视差的点的个数

本文。。。。。

本文在训练数据集中每一个非零视差的图像位置处提取一对积极的和一对消极的示例，一个积极示例的图像块是将右图像快的中心设置为。。。。
同理一对消极示例是将右图像块的中心设置为。。。

积极示例和消极示例的图像块还需要通过将图像的像素强度值减去它们的平均值再除以标准差来归一化，

本文将归一化后的积极示例和消极示例随机混合在一起，以1:1的比例构成一批128对的图像块，这就是我们最终的训练数据集

接下来我将详细介绍一下本文的立体匹配算法设计  
算法分为  

本文使用卷积神经网络来初始化立体匹配代价，网络结构如图所示，主要参考了Simese网络的结构，本文通过计算余弦相似度来计算相似度得分，余弦相似性的公式为。。。
可分解为L2归一化和点积.网络的损失通过计算铰链损失得到

所得的相似度得分取负号来得到最终的匹配代价。

接下来介绍左右一致性检查，
令D^L表示通过以左图为参考图得到的视差图，D^R表示以右图为参考图得到的视差图

接下来我们应用以下规则来标记所有点，

随后我们通过半全局匹配来改善匹配代价，

半全局匹配通过使一个依赖于视差图D的能量函数E(D)最小化来求解最优视差

通常我们通过动态规划单一方向上的能量函数最小化来实现ED的最小化。

第一项表示Siamese网络计算所得的匹配代价，第二项是四个候选值中的最小值。第一个候选值是之前所有像素视差值取d时的最小匹配代价，第二个候选值是之前所有像素视差值取d-1时的最小匹配代价与惩罚系数 P_1之和，第三个候选值是之前所有像素视差值取d+1时的最小匹配代价与惩罚系数 P_1之和，第四个候选值是之前所有像素视差值取其他值时的最小匹配代价与惩罚系数 P_2之和。第三项是之前所有像素视差值取其他值时的最小匹配代价，这一项是为了防止C_r (p,d)的值过大影响视差图的优化。

最终的匹配代价是所有四个方向上取平均值得到。

为消除视差图的某些异常点平滑视差图，本文通过中值滤波和双边滤波来进一步的精化视差。

中值滤波和双边滤波都是通过OpenCV实现的，涉及到的超参数有。。。。。

接下来介绍，立体视觉实现与运行
整个立体视觉系统由四个部分组成

本文采用两个单目摄像头组合组成双目摄像头，参数如表所示。

摄像头通过棋盘标定法标定，
棋盘由黑白相间的正方形组成，为达到最好的标定效果，棋盘的长和宽的方格数必须要有一个为偶数，一个为奇数。本文的棋盘方格数为6×9，实际打印后每个正方形的边长为29mm，棋盘被固定在一硬纸箱底部。本文选取了15组不同的图像对进行标定

本文采用Matlab离线标定所得参数，并通过OpenCV实现双目矫正和三维恢复。
Matlab的离线矫正是一个自动化的过程，矫正误差约为0.19，基本满足需求。
OpenCV的双目矫正和三维恢复也有一套标准的流程，就不再赘述了

本文通过前文所说的训练数据集训练神经网络，卷积神经网络的具体参数如表，

本文通过胜者全拿的策略得到初始视差，即对每个像素点p寻找使匹配代价最小的视差值d。考虑到本文计算量较大，我们通过以下三个细节来提高算法效率。。。

最后本文通过KITTI的误差计算方式来计算匹配误差，约为8.0%

本文搭建了服务器和客户端UI界面来展示整套的双目立体视觉系统

由于本文使用的GPU服务器位于学校内网之中，本文采用Ngrok工具来进行内网穿透，并通过Flask搭建Web服务器。

客户端的UI设计如上所示，最终结果经过伪彩化处理。。











无人坦克，无人驾驶，机器人导航


激光雷达

Velodyne 激光雷达价格
8000-80000美金
三家激光雷达
http://www.leiphone.com/news/201605/gRdue1eegZEAkBaQ.html

http://www.roboticschina.com/news/article/driverless-sensor

https://wallstreetcn.com/articles/258077

存在两个缺陷：
1.成本高昂，呈下降趋势
2.激光雷达 垂直分辨率较小，问题还没有解决方案


目前市场上的双目视觉解决方案通常采用激光雷达和摄像机相结合的方案。通过激光雷达的高分辨率来弥补摄像机的不足
