## 文献综述  

引言（不分点）
立体视觉的历史
三类方法
双目视觉一般步骤
应用

卷积神经网络
发展历史
网络结构

立体匹配技术的研究及发展现状

立体匹配算法的发展

区域匹配
SIFT算法
LeCun的两大结构

标签数据集
KITTI
Middlebury

总结




### 摘要：
立体视觉技术的发展和现状，介绍了立体视觉研究的三类方法，以及立体视觉技术在人工智能领域发挥的巨大作用  

立体匹配算法的不断改进和发展，及卷积神经网络技术在立体匹配算法中的应用。    

当前主要立体匹配算法及优缺点以及双目视觉立体匹配算法设计的研究意义  

关键词：立体视觉、双目视觉、立体匹配  

### 前言
近年来，立体视觉技术成为计算机视觉研究中日益受关注的方向。随着深度学习技术在计算机视觉图像处理领域的快速发展，越来越多的学者开始使用深度学习算法进行立体视觉匹配。首先我们来介绍一下几个名词在本文中的含义：

**立体视觉**：立体视觉是指通过计算机技术或光学手段获得可见对象的深度和距离的过程。它是计算机视觉领域的一个重要课题，目的是重构场景的三维几何信息。  
**双目立体视觉**：双目立体视觉是立体视觉实现的常见方法，它是基于视差原理并由两幅图像获取场景的三维几何信息的方法。双目立体视觉系统一般由双摄像机从不同角度同时获得被测场景的两幅数字图像，或由单摄像机在不同时刻从不同角度获得被测场景的两幅数字图像，并基于视差原理恢复出场景的三维几何信息，重建场景中物体的三维轮廓及位置。  
**极线约束**：
**立体匹配**：立体视觉匹配是立体视觉技术中的核心问题，它的目标是从不同视点图像中找到匹配的对应点。根据对应点计算所得的视差用于图像场景的三维几何重构。
**特征学习**：特征学习是学习一个特征的技术的集合，将原始数据转换成为能够被机器学习来有效开发的一种形式。它避免了手动提取特征的麻烦，允许计算机学习使用特征的同时，也学习如何提取特征：学习如何学习。特征学习的目标是寻求更好的表示方法并建立更好的模型来从大规模未标记数据中学习这些表示方法。
**深度学习**：深度学习是机器学习中一种基于对数据进行特征学习的方法，它把原始数据通过一些简单的但是非线性的模型转变成为更高层次的，更加抽象的表达。通过足够多的转换的组合，非常复杂的函数也可以被学习。
**卷积神经网络（CNN）**：卷积神经网络是深度学习技术中极具代表性的一种，它是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。卷积神经网络由一个或多个卷积层和顶端的全连通层组成，同时也包括关联权重和池化层。这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更优的结果。这一模型也可以使用反向传播算法进行训练。相比较其他深度、前馈神经网络，卷积神经网络需要估计的参数更少，使之成为一种颇具吸引力的深度学习结构。

### 正文
自然界中的物体都是三维的，人类通过双眼可以获取物体的三维立体信息。但一般的摄影系统只能把三维的物体以二维的形式保存和记录下来，同时丢失了大量的信息。



自20世纪80年代美国麻省理工学院人工智能实验室的Marr首次提出完整的机器视觉系统计算理论框架以来，立体视觉技术 应用于双眼匹配，双目视觉直接模拟 人类双眼处理景物的方式，可靠简便，在许多领 域均极具应用价值。


立体视觉研究的三类方法：

第一类方法，也就是程距法 (range data method)，根据已知的深度图，用数值逼近的方法重建表面信息，根据模型建立场景中的物体描述，实现图象理解功能。这是一种主动方式的立体视觉方法，其深度图是由测距器(range finders)获得的，如结构光(structured light)、激光测距器(laser range finders) 等其他主动传感技术 (active sensing techniques)。这类方法适用于严格控制下的环境(tightly controlled domains)，如工业自动化的应用方面。

第二类方法，依据光学成象的透视原理及统计假设，根据场景中灰度变化导出物体轮廓及表面，由影到形(shape from shading)，从而推断场景中的物体。线条图的理解就是这样的一个典型问题，曾经引起了普遍的重视而成为计算机视觉研究领域的一个焦点，由此产生了各种各样的线条标注法。这种方法的结果是定性的，不能确定位置等定量信息，该方法由于受到单一图象所能提供信息的局限性，存在难以克服的困难。

第三类方法，利用多幅图象来恢复三维信息的方法，它是被动方式的。根据图象获取方式的区别又可以划分成普通立体视觉和通常所称的光流(optical flow)两大类。普通立体视觉研究的是由两摄像机同时拍摄下的两幅图象，而光流法中研究的是单个摄像机沿任一轨道运动时顺序拍下的两幅或更多幅图象。前者可以看作后者的一个特例，它们具有相同的几何构形，研究方法具有共同点。双目立体视觉是它的一个特例。


双目立体视觉基本原理是从两个视点观察同一景物 以获取立体图像对,匹配出对应点,从而计算出视差并获得三维信息.

基本原理介绍

双目立体视觉的一般步骤介绍：
相机内参外参的离线标定
双目矫正
立体匹配
三角测量

其中立体匹配是双目视觉技术的核心步骤。
立体匹配的算法发展：

早期的立体匹配是基于小窗口的区域匹配，提取的特征值大多为灰度、颜色等信息。后来开发出自 适应窗口技术，针对特征值也开发出对光照鲁棒 性的变换值，如 Census变换等。近年来，基于全局 的立体匹配技术成为人们研究的热点，其大致思 路为：提取特征值光流场特征、边缘特征、Harris 角 点特征、SIFY 特征向量、SURF 特征等可靠特征，计 算出初步视差图，再由全局优化函数(动态规划、 图像分割、置信传播等)对整幅图像的视差值进行 迭代优化分配计算。

最简单的的匹配算法利用匹配点周围一个固定大小的窗口的灰度分布，在一个可能的视差范围内，通过寻找两个对应窗口图像向量的归一化相关值的最大值得到视差，这一类方法也被称为“区域匹配”方法（Area Matching）。区域匹配的一个假设是空间的平面是所谓的正平面，也就是与相机平面平行的平面，而实际的场景中存在着大量的非正平面，因此人们开始考虑利用一些更有意义的特征点（感兴趣点）来进行匹配， 这种方法也被称为特征匹配（Feature Matching）方法，如 Marr和 Poggio 提出了多尺度的匹配算法，利用不同的 Laplacian 过零点以及梯度进行匹配。


最简单的算法
单点比较法：对于目标图像上的点p，在参考图像极线上寻找强度值相近的点
窗口匹配法，对于目标图像上的点p，在参考图像极线上寻找对应点，并通过图像上一个正方形窗口区域来衡量匹配程度
窗口匹配法相对于单点比较法有所改进，但是匹配效果受窗口尺寸影响大，而且没有最优窗口尺寸能解决所有问题，同时还存在弱纹理，前景放大等问题，实际应用效果不佳。

当前常规的匹配算法一般通过特征点来做，即分别提取左右图像的特征点(常用sift算法)，然后基于特征点配合对极几何等约束条件进行匹配。

SIFT算法：基于SIFT特征的立体匹配算法由Lowe D G 1999年首次提出，2004年完善总结，其全称是Scale Invatiant Feature Transform，即尺度不变特征变换。SIFT算法是一种提取局部特征的算法，在尺度空间中寻找极值点，提取位置、尺度、旋转不变量，生成关键点特征描述符，然后根据这些不变量特征进行匹配。


2015年，Jure Zbontar和Yann LeCun首次在CVPR上提出使用卷积神经网络来计算立体匹配代价，并在2016年进一步完善，在主流评测库MiddleBury和KITTI中基于卷积神经网络的立体视觉匹配算法仍然排在前列。



参考文献：
[1]周星，高志军.立体视觉技术的应用与发展[A].工程图学学报,2010年第4期，No.4.
[2]艾海舟、张朋飞、何克忠、江潍、张军宇.室外移动机器人的视觉临场感系统[J].机器人，22（1）：28-32，2000

[3]	Hubel D H, Wiesel T N. Receptive fields, binocular interaction and functional architecture in the cat's visual cortex[J]. The Journal of physiology, 1962, 160(1): 106-154.
[4]	Fukushima K, Miyake S. Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position[J]. Pattern recognition, 1982, 15(6): 455-469.
[5]	LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.
[6]Hinton G E, Osindero S, Teh Y, et al. A fast learning algorithm for deep belief nets[J]. Neural Computation, 2006, 18(7): 1527-1554.


**KITTI数据集**
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: the KITTI dataset. International Journal of Robotics Research (IJRR), 2013.

Fatma Guney and Andreas Geiger. Displets: Resolving stereo ambiguities using object knowledge. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.

**MiddleBury**
Daniel Scharstein and Chris Pal. Learning conditional random fields for stereo. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2007.

Daniel Scharstein and Richard Szeliski. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. International Journal of Computer Vision, 47(1-3): 7–42, 2002.

Daniel Scharstein and Richard Szeliski. High-accuracy stereo depth maps using structured light. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June.2003.

Daniel Scharstein, Heiko Hirschmu¨ller, York Kitajima, Greg Krathwohl, Nera Neˇsi´c, Xi Wang, and Porter Westling. High-resolution stereo datasets with subpixel-accurate ground truth. German Conference on Pattern Recognition (GCPR), September 2014.




[6]Yann LeCun,Yoshua Bengio,Geoffrey Hinton.Deep learning[J].Nature 521, 436–444 (28 May 2015)

[7]Marr D C.A Computational Investigation into the Human
Representation and Processing of Visual  Information [M]．San Francisco：W．H．Freeman and company，1982．
[8]Jure Žbontar and Yann LeCun. Computing the stereo matching cost with a convolutional neural network. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.
[9]Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,20004,60(2):91-110.
